{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python으로 텍스트 바꾸기 (정규식)\n",
    "- 텍스트 파일을 읽은 후 필요한 정보만 추출한다.\n",
    "- 텍스트 파일을 읽은 후 텍스트 내용을 변환한다.\n",
    "- 텍스트 파일을 읽고 수정한 후 다른 이름으로 저장한다.\n",
    "\n",
    "- 대상 텍스트 파일: Moby Dick"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 텍스트 파일 처리: 정규식(regular expressions)\n",
    "- 정규식: 문자열의 검색과 치환을 위한 형식 언어이다. 텍스트 파일을 처리할 때 가장 많이 수행하는 작업 중 하나가 정규식을 이용한 문자열 검색과 문자열 찾기/바꾸기이다.\n",
    "- 몇 개의 파일을 대상으로 고정된 형태의 문자열을 찾기/바꾸기하는 것은 워드프로세서로도 가능하지만 대량의 파일을 처리할 때는 워드프로세서로 처리하는 것이 쉽지 않다.\n",
    "- 고정된 문자열이 아닌 가변형의 문자열은 정규식을 이용해야 한다.\n",
    "- 정규식의 문법 체계와 활용 범위는 아주 방대하므로 여기서는 한글 말뭉치 텍스트를 다룰 때 가장 기본적인 것 몇 가지만 소개한다.\n",
    "- 보다 다양한 정규식 형태에 대한 설명은 https://www.regular-expressions.info/나 https://rstudio-pubs-static.s3.amazonaws.com/74603_76cd14d5983f47408fdf0b323550b846.html 등을 참고하면 된다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 정규식을 이용한 문자열의 검색과 치환\n",
    "- *re* 라이브러리를 사용한다.\n",
    "- 정규식을 이용한 문자열 찾기는 match(), search(), findall()을, 문자열 치환은 sub() 함수를 사용한다.\n",
    "- search() 함수는 찾고자 하는 문자열 패턴의 위치와 해당 문자열을 반환한다.\n",
    "- findall() 함수는 찾고자 하는 문자열과 일치하는 모든 문자열을 반환한다.\n",
    "- sub() 함수는 찾는 문자열을 원하는 다른 문자열로 변환한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 문자열 찾기: search, match, findall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex = 'an example word:cat!!'\n",
    "searched = re.search(pattern='word:...', string=ex)\n",
    "# match = re.search('word:[a-z]+', ex)\n",
    "\n",
    "if searched:\n",
    "  print(searched.group())\n",
    "else:\n",
    "  print('Nothing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex = 'an example word:cat!!'\n",
    "searched = re.search(pattern='word:[a-z]+', string=ex)\n",
    "\n",
    "if searched:\n",
    "  print(searched.group())\n",
    "else:\n",
    "  print('Nothing')\n",
    "\n",
    "print(matched)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **search()**, **match()**, **findall()** 함수의 차이"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(re.match('a', 'aba'))\n",
    "print(re.match('a', 'bbb'))\n",
    "print(re.match('a', 'baa'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(0, 1), match='a'>\n",
      "None\n",
      "<re.Match object; span=(1, 2), match='a'>\n"
     ]
    }
   ],
   "source": [
    "print(re.search('a', 'aba'))\n",
    "print(re.search('a', 'bbb'))\n",
    "print(re.search('a', 'baa'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(re.findall('a', 'aba'))\n",
    "print(re.findall('a', 'bbb'))\n",
    "print(re.findall('a', 'baa'))\n",
    "print(re.findall('aaa', 'aaaa'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. 특정 패턴의 단어 추출: **search()** 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['abaissed', 'abandoned', 'abased', 'abashed', 'abatised', 'abed', 'aborted', 'abridged', 'abscessed', 'absconded']\n",
      "['abjectly', 'adjuster', 'coprojector', 'dejectly', 'injector', 'interjector', 'majestic', 'microprojector', 'munjistin', 'objectee']\n",
      "['gold', 'golf', 'hold', 'hole']\n"
     ]
    }
   ],
   "source": [
    "with open('../data/english_wordlist.txt', 'r') as f:\n",
    "  wordlist = f.read().splitlines()\n",
    "\n",
    "searched_1 = []\n",
    "searched_2 = []\n",
    "searched_3 = []\n",
    "for word in wordlist:\n",
    "  if re.search('ed$', word):\n",
    "    searched_1.append(word)\n",
    "  elif re.search('..j..t..$', word):\n",
    "    searched_2.append(word)\n",
    "  elif re.search('^[ghi][mno][jlk][def]$', word):\n",
    "    searched_3.append(word)\n",
    "\n",
    "print(searched_1[:10])\n",
    "print(searched_2[:10])\n",
    "print(searched_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = re.search('ed$', 'abaissed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ed'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.group()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 1-2행: 영어 단어 목록을 담은 텍스트 파일을 읽어 *wordlist*에 저장한다. **splitlines()** 함수는 **read()**로 읽은 문자열에서 엔터('\\n')를 기준으로 분리해 준다. 즉 **f.read()**로 읽은 텍스트에 **splitlines()**를 적용하여 한 단어가 한 줄로 읽히게끔 만든다. 이에 따라 *wordlist*의 길이(**len(wordlist)**)는 총 210,687, 즉 210,687개 단어이다(notepad++로 english_wordlist.txt 파일을 열어 확인할 수 있다). \n",
    "1. 4-6행: **search()** 함수로 찾은 단어를 저장한 리스트 변수 3개를 미리 만들어둔다.\n",
    "1. 7행: *wordlist*에서 한 단어씩 꺼내서 *word*에 할당하고 이 *word*에 대해서\n",
    "1. 8행: 만약(**if**) 패턴 'ed$'가 *word* 내에 존재하면 \n",
    "   \\$는 문자열의 끝을 의미하므로 ed\\$는 ed로 끝나는 단어(e.g. watched, searched)를 의미한다. 즉 *word*가 ed로 끝나는 단어인지 판단해서 패턴에 해당하는 문자열을 반환한다. 반환하는 값이 있으면 **re.search()**는 None이 아니므로 if 조건문에서는 True(참)가 반환된다.\n",
    "1. 9행: 그 단어(*word*)를 search_1 리스트에 저장하고\n",
    "1. 10행: 그렇지 않고 만약(**elif**: else if) 패턴 '..j..t..$'가 *word* 내에 존재하면\n",
    "   패턴에서 ..는 아무 문자나 두 개를 의미한다. ..t는 아무 문자나 두 개 다음에 알파벳 j가 나오는 패턴을 의미한다. 따라서 '..j..t..$'는 아무 문자나 두 개 다음에 j가 나오고 이어 아무 문자나 두 개가 나온 다음에 t가 나오고 다음에 아무 문자나 두 개로 끝나는 단어(e.g. ma-j-est-ic)를 의미한다.\n",
    "1. 11행: 그 단어(*word*)를 search_2 리스트에 저장하고\n",
    "1. 12행: 그렇지 않고 만약(**elif**: else if) 패턴 '^[ghi][mno][jlk][def]$'가 *word* 내에 존재하면\n",
    "   패턴에서 ^는 문자열의 제일 첫 부분, 즉 여기서는 단어의 처음 위치를 의미한다. [ghi]는 g 혹은 h 혹은 i 중의 하나를 뜻한다. 따라서 '^[ghi][mno][jlk][def]$'는 단어의 첫 알파벳이 g나 h나 i로 시작하고 그 다음 알파벳은 m이나 n이나 o이며, ... 마지막 알파벳이 d 혹은 e 혹은 f로 끝나는 단어(e.g. gold)를 말한다. \n",
    "1. 13행: 그 단어(*word*)를 search_3 리스트에 저장한다.\n",
    "1. 15-17행: *searched_1*의 10개 요소, *searched_2*의 10개 요소, *searched_3* 전체 요소를 출력한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['miiiiiiiiiiiiinnnnnnnnnnneeeeeeeeee', 'miiiiiinnnnnnnnnneeeeeeee', 'mine', 'mmmmmmmmiiiiiiiiinnnnnnnnneeeeeeee']\n",
      "['', 'e', 'i', 'in', 'm', 'me', 'meeeeeeeeeeeee', 'mi', 'min', 'mm']\n",
      "['a', 'aaaaaaaaaaaaaaaaa', 'aaahhhh', 'ah', 'ahah', 'ahahah', 'ahh', 'ahhahahaha', 'ahhh', 'ahhhh', 'ahhhhhh', 'ahhhhhhhhhhhhhh', 'h', 'ha', 'haaa', 'hah', 'haha', 'hahaaa', 'hahah', 'hahaha', 'hahahaa', 'hahahah', 'hahahaha', 'hahahahaaa', 'hahahahahaha', 'hahahahahahaha', 'hahahahahahahahahahahahahahahaha', 'hahahhahah', 'hahhahahaha']\n"
     ]
    }
   ],
   "source": [
    "with open('../data/chat_words.txt', 'r') as f:\n",
    "  chatwords = f.read().splitlines()\n",
    "\n",
    "searched_1 = []\n",
    "searched_2 = []\n",
    "searched_3 = []\n",
    "for word in chatwords:\n",
    "  if re.search('^m+i+n+e+$', word):\n",
    "    searched_1.append(word)\n",
    "  elif re.search('^m*i*n*e*$', word):\n",
    "    searched_2.append(word)\n",
    "  elif re.search('^[ha]+$', word):\n",
    "    searched_3.append(word)\n",
    "\n",
    "print(searched_1[:10])\n",
    "print(searched_2[:10])\n",
    "print(searched_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6066"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chatwords)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 1-2행: 채팅 단어 목록을 담은 텍스트 파일을 읽어 *chatwords*에 저장한다. **splitlines()** 함수는 **read()**로 읽은 문자열에서 엔터('\\n')를 기준으로 분리해 준다. 즉 **f.read()**로 읽은 텍스트에 **splitlines()**를 적용하여 한 단어가 한 줄로 읽히게끔 만든다. 이에 따라 *chatwords*의 길이(**len(chatwords)**)는 총 6.066이다. \n",
    "1. 4-6행: **search()** 함수로 찾은 단어를 저장한 리스트 변수 3개를 미리 만들어둔다.\n",
    "1. 7행: *chatwords*에서 한 단어씩 꺼내서 *word*에 할당하고 이 *word*에 대해서\n",
    "1. 8행: 만약(**if**) 패턴 '^m+i+n+e+$'가 *word* 내에 존재하면\n",
    "   정규식에서 +는 바로 앞의 문자 패턴 1개 이상을 의미한다. m+는 m이 하나 혹은 두 개 이상인 경우(e.g. mine, mmmnnnn)를 의미한다. '^m+i+n+e+$'는 첫 글자가 m이고 m이 한번 이상 나타나고 이어서 i가 한번 이상 나타나고 이어서 n이 한번 이상, 마지막으로 e가 한번 이상 나타난 후에 끝나는 단어를 말한다.\n",
    "1. 9행: 그 단어(*word*)를 search_1 리스트에 저장하고\n",
    "1. 10행: 그렇지 않고 만약(**elif**: else if) 패턴 '^m\\*i\\*n\\*e\\*$'가 *word* 내에 존재하면\n",
    "   정규식에서 \\*는 바로 앞의 문자 패턴 0개 혹은 1개 이상을 의미한다. m*는 m이 안 나타나거나 한번 이상 나타나는 경우를 의미한다. '^m\\*i\\*n\\*e\\*$'는 첫 글자가 하나 이상의 m 혹은 m이 아니고 이어서 하나 이상의 i 혹은 i가 아니며 이어서 n이 한번 이상 혹은 나타나지 않으며 아지막으로 e가 한번 이상 혹은 나타나지 않는 단어를 말한다.  \n",
    "1. 11행: 그 단어(*word*)를 search_2 리스트에 저장하고\n",
    "1. 12행: 그렇지 않고 만약(**elif**: else if) 패턴 '^[ha]+$'가 *word* 내에 존재하면\n",
    "   '^[ha]+$'는 첫 글자가 h 혹은 a이고 h 혹은 a가 한번 이상 나타난 후 끝나는 단어를 말한다.\n",
    "1. 13행: 그 단어(*word*)를 search_3 리스트에 저장한다.\n",
    "1. 15-17행: *searched_1*의 10개 요소, *searched_2*의 10개 요소, *searched_3* 전체 요소를 출력한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0.0085', '0.05', '0.1', '0.16', '0.2', '0.25', '0.28', '0.3', '0.4', '0.5']\n",
      "['1614', '1637', '1787', '1901', '1903', '1917', '1925', '1929', '1933', '1934']\n",
      "['10-day', '10-lap', '10-year', '100-share', '12-point', '12-year', '14-hour', '15-day', '150-point', '190-point', '20-point', '20-stock', '21-month', '237-seat', '240-page', '27-year', '30-day', '30-point', '30-share', '30-year', '300-day', '36-day', '36-store', '42-year', '50-state', '500-stock', '52-week', '69-point', '84-month', '87-store', '90-day']\n",
      "['62%-owned', 'Absorbed', 'According', 'Adopting', 'Advanced', 'Advancing', 'Alfred', 'Allied', 'Annualized', 'Anything']\n"
     ]
    }
   ],
   "source": [
    "with open('../data/treebank_words.txt', 'r') as f:\n",
    "  treebankwords = f.read().splitlines()\n",
    "\n",
    "searched_1 = []\n",
    "searched_2 = []\n",
    "searched_3 = []\n",
    "searched_4 = []\n",
    "for word in treebankwords:\n",
    "  if re.search('^[0-9]+\\.[0-9]+$', word):\n",
    "    searched_1.append(word)\n",
    "  elif re.search('^[0-9]{4}$', word):\n",
    "    searched_2.append(word)\n",
    "  elif re.search('^[0-9]+-[a-z]{3,5}$', word):\n",
    "    searched_3.append(word)\n",
    "  elif re.search('(ed|ing)$', word):\n",
    "    searched_4.append(word)\n",
    "\n",
    "print(searched_1[:10])\n",
    "print(searched_2[:10])\n",
    "print(searched_3)\n",
    "print(searched_4[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bool(re.search('^[0-9]{4}$', word))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 1-2행: 트리뱅크(코퍼스의 일종) 단어 목록을 담은 텍스트 파일을 읽어 *treebankwords*에 저장한다. **splitlines()** 함수는 **read()**로 읽은 문자열에서 엔터('\\n')를 기준으로 분리해 준다. 즉 **f.read()**로 읽은 텍스트에 **splitlines()**를 적용하여 한 단어가 한 줄로 읽히게끔 만든다. 이에 따라 *treebankwords*의 길이(**len(treebankwords)**)는 총 12,408이다. \n",
    "1. 4-6행: **search()** 함수로 찾은 단어를 저장한 리스트 변수 3개를 미리 만들어둔다.\n",
    "1. 7행: *wordlist*에서 한 단어씩 꺼내서 *word*에 할당하고 이 *word*에 대해서\n",
    "1. 8행: 만약(**if**) 패턴 '^[0-9]+\\.[0-9]+$'가 *word* 내에 존재하면\n",
    "   패턴 '^[0-9]+'는 단어의 처음이 숫자 하나 이상으로 시작하는 것을 말한다. '\\.'는 정규식 패턴인 아무 문자 하나를 의미하는 것이 아니라 문자 그대로의 .을 의미한다. 문자 그대로의 .을 찾는다는 것을 표시하기 위해 이스케이프 문자 \\를 앞에 붙인다(만약 +앞에 이스케이프 문자 \\를 붙여 \\+로 표시하면 바로 앞의 글자 하나 이상을 의미하는 것이 아니라 문자 그대로의 + 기호를 뜻하는 것이다). 따라서 '^[0-9]+\\.[0-9]+$'는 숫자로 시작하고 .이 나온 다음 숫자로 끝나는 단어들을 말한다.\n",
    "1. 9행: 그 단어(*word*)를 search_1 리스트에 저장하고\n",
    "1. 10행: 그렇지 않고 만약(**elif**: else if) 패턴 '^[0-9]{4}$'가 *word* 내에 존재하면\n",
    "   {} 안에 숫자 n으로 표기된 것은 바로 앞의 문자가 n개 나오는 경우를 말한다. '^[0-9]{4}$'는 숫자로 시작하고 숫자가 4자리로 된 단어들 말한다.\n",
    "1. 11행: 그 단어(*word*)를 search_2 리스트에 저장하고\n",
    "1. 12행: 그렇지 않고 만약(**elif**: else if) 패턴 '^[0-9]+-[a-z]{3,5}$'가 *word* 내에 존재하면\n",
    "   {} 안에 숫자 m, n으로 표기된 것은 바로 앞의 문자가 m개 이상 n개 이하 있다는 것을 의미한다. '^[0-9]+-[a-z]{3,5}$'는 숫자가 적어도 하나 이상 나오고 -가 나온 후 알파벳 문자가 3개 이상 5개 이하 나타난 후에 끝나는 단어(e.g. 10-day, 10-lap)를 나타낸다.\n",
    "1.  13행: 그 단어(*word*)를 search_3 리스트에 저장한다.\n",
    "1. 12행: 그렇지 않고 만약(**elif**: else if) 패턴 '(ed|ing)$'가 *word* 내에 존재하면\n",
    "    정규식에서 |는 or의 의미이다. 즉 ed 혹은 ing로 끝나는 단어를 말한다.\n",
    "1. 13행: 그 단어(*word*)를 search_3 리스트에 저장한다.\n",
    "1. 15-17행: *searched_1*의 10개 요소, *searched_2*의 10개 요소, *searched_3* 전체 요소를 출력한다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. 어간과 접사 분리하기(stemming): **findall()**을 사용하여"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ist', 'ly', 'ed', 'ed', 'ly', 'ment', 'ed', 'ly', 'ness', 'ment', 'ed', 'ly', 'ness', 'ly', 'ment', 'ment', 'ed', 'es', 'ly', 'ive', 'ive', 'ly', 'ed', 'ment', 'ly', 'ing', 'ing', 'ly', 'ness', 'ist', 'ly', 'ist', 'ly', 'ive', 'ness', 'ive', 'ly', 'ness', 'ive', 'ment', 'ious', 'ive', 'ness', 'ly', 'ly', 'ive', 'ist', 'ly', 'ness', 'ment']\n"
     ]
    }
   ],
   "source": [
    "pattern = '^.*(ing|ly|ed|ist|ious|ies|ive|es|ment|ness)$'\n",
    "\n",
    "with open('../data/english_wordlist.txt', 'r') as f:\n",
    "  wordlist = f.read().splitlines()\n",
    "\n",
    "word_endings = []\n",
    "for word in wordlist:\n",
    "  stemming = re.findall(pattern, word)\n",
    "  if stemming is not None:\n",
    "    word_endings.extend(stemming)\n",
    "\n",
    "print(word_endings[:50])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 1행: 찾고자 하는 패턴을 *pattern* 변수에 저장한다. ''^.*'는 아무 문자나 0번 혹은 1번 이상 나타나는 단어를 말한다. (ing|ly|ed|ist|ious|ies|ive|es|ment|ness)는 |를 사용하여 10개 문자열을 or로 연결한 것이다. 즉 ing 혹은 ly 혹은 ... ness 앞에 아무 문자나 0번 혹은 1번 이상 나타나는 경우, 즉 이 문자열들로 끝나는 모든 단어들을 말한다. \n",
    "1. 3-4행: 영어 단어 목록을 담은 텍스트 파일을 읽어 *wordlist*에 저장한다.\n",
    "1. 6행: 접미사 목록을 저장할 빈 리스트 *word_endings*를 만든다.\n",
    "1. 7행: *wordlist*에서 단어를 하나씩 가져와서 *word*에 할당한 후\n",
    "1. 8행: *word*에서 1행에서 지정한 패턴에 해당하는 문자열을 모두 찾아(**re.findall()**) *stemming*에 저장한다.\n",
    "1. 9행: 만약 *steemming*이 빈 것이 아니라면, 즉 패턴에 해당하는 문자열을 찾아 정보를 저장하고 있다면\n",
    "1. 10행: 6행에서 만든 *word_endings* 리스트에 넣어준다. 이 때 **append()**가 아니라 **extend()**를 사용한 것은 *stemming*이 리스트로 반환되어 이 리스트를 *word_endings* 리스트에 개별 요소 단위로 추가해야 하기 때문이다.\n",
    "1. 12행: *word_endings*을 50개까지 출력한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abac\tist\n",
      "abactinal\tly\n",
      "abaiss\ted\n",
      "abandon\ted\n",
      "abandoned\tly\n",
      "abandon\tment\n",
      "abas\ted\n",
      "abased\tly\n",
      "abased\tness\n",
      "abase\tment\n"
     ]
    }
   ],
   "source": [
    "pattern_1 = '^(.*?)(ing|ly|ed|ist|ious|ies|ive|es|ment|ness)$'\n",
    "\n",
    "word_roots = []\n",
    "word_endings = []\n",
    "for word in wordlist:\n",
    "  matched = re.findall(pattern_1, word)\n",
    "  if matched:\n",
    "    matched = matched[0]\n",
    "    root = matched[0]\n",
    "    ending = matched[1]\n",
    "    word_roots.append(root)\n",
    "    word_endings.append(ending)\n",
    "\n",
    "for root, ending in zip(word_roots[:10], word_endings[:10]):\n",
    "  print(root + '\\t' + ending)\n",
    "\n",
    "with open('../result/word_root_endings.txt', 'w') as f:\n",
    "    for root, ending in zip(word_roots, word_endings):\n",
    "      f.writelines(root + '\\t' + ending + '\\n') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('abac', 'ist')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = [i for i, word in enumerate(wordlist) if re.search('abacist', word)]\n",
    "matched = re.findall(pattern_1, wordlist[15])\n",
    "matched"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 1행: 찾고자 하는 패턴을 *pattern_1* 변수에 저장한다. 바로 위의 *pattern*과 차이는 '.\\*' 대신 '((.*?))'이 사용된 점이다. 정규식 메타 문자 \\*는 매칭 가능한 최대 범위의 문자열을 찾는 반면, ?를 추가하면 매칭 가능한 최소한의 문자열을 찾는다. 둘의 차이점은 아래의 코드 블록에서 설명한다(\\* 단, 위 코드에서는 ?를 사용하지 않아도 원하는 결과를 얻을 수 있다). \n",
    "   '^(.*?)(ing|ly|ed|ist|ious|ies|ive|es|ment|ness)$'는 아무 문자로 시작하되 ing, ly, ed, ... 등으로 끝나는 단어를 찾으라는 의미이다. ()는 그룹을 지정하기 위한 것으로 '(.\\*?)'와 (ing|ly|ed|ist|ious|ies|ive|es|ment|ness) 등 두 개를 각개의 그룹으로 취급한다는 의미이다. 즉 패턴에 맞는 단어가 나타날 경우 첫 번째 괄호에 해당하는 어간과 두 번째 괄호에 해당하는 접미사를 분리하여 저장한다.\n",
    "1. 3-4행: 단어의 어간(root, stem)을 저장할 *word_roots*와 접미사를 저장할 *word_endings* 변수를 만든다.\n",
    "1. 5행: *wordlist*의 각 *word*에 대해\n",
    "1. 6행: *pattern_1*과 일치하는 모든 문자열을 찾아 *matched*에 저장한다.\n",
    "1. 7행: 만약 패턴에 일치하는 정보가 있어 *matched*에 저장되어 있다면 (즉 찾은 정보가 저장되어 있다면)\n",
    "1. 8행: *matched*에는 리스트 내에 어간과 접미사가 (어간, 접미사)의 쌍으로 저장되어 있으므로 어간과 접미사 정보를 확인하려면 인덱스 번호를 이용하여 리스트 안에 있는 쌍 정보에 접근해야 한다. 리스트 안에는 하나의 쌍만 존재하므로 0번 인덱스를 지정하여 쌍 정보를 얻은 후 이를 다시 *matched*에 저장한다.\n",
    "1. 9행: 어간은 (어간, 접미사) 쌍에서 첫 번째 요소이므로 0번째 인덱스, 즉 matched[0]으로 어간을 얻은 후 *root*에 저장한다.\n",
    "1. 10행: 접미사는 (어간, 접미사) 쌍에서 두 번째 요소이므로 1번째 인덱스, 즉 matched[1]으로 접미사를 얻은 후 *ending*에 저장한다.\n",
    "1. 11-12행: *root*와 *ending*을 *word_roots*와 *word_endings*에 각각 순차적으로 추가한다.\n",
    "1. 14-15행은 어간과 접미사를 10개씩만 출력하되 어간-접미사 의 형태로 출력하라는 명령이다.\n",
    "1. 14행: *word_roots*와 *word_endings*에서 각각 10개씩 단어를 추출하여 **zip()**으로 묶고, 어간과 접미사의 쌍을 하나씩 꺼내어 *root*와 *ending*에 할당한다.\n",
    "1. 15행: *root*와 *ending*을 연결하되 사이에 탭(\\t) 공백을 삽입한 후 출력한다.\n",
    "1. 17-19행은 어간과 접미사를 분리한 전체 목록을 파일로 저장하라는 명령이다.\n",
    "1. 17행: **with open()** 함수로 result 폴더에 word_root_endings.csv라는 파일 이름을 만들어 내용을 적기 위한 준비를 한다. 이 파일은 엑셀에서 스프레드시트 형식으로 열 수 있고, 엑셀 파일로 변환할 수 있다. \n",
    "1. 18행: *word_roots*와 *word_endings*에서 단어들을 추출하여 **zip()**으로 묶고, 어간과 접미사의 쌍을 하나씩 꺼내어 *root*와 *ending*에 할당한다.\n",
    "1. 19행: *root*와 *ending*을 탭(\\t) 공백으로 연결하되 마지막에 엔터(\\n)를 추가하여 각 단어가 별개 라인으로 저장된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "sents = [\"Social worker: Great. Did you bring it with you?\",\n",
    "          \"사회복지사: 잘 하셨어요. 일기 가지고 오셨나요?\",\n",
    "          \"Joker: (dodging the subject) I'm sorry. Did I bring what?\",\n",
    "          \"조커: (못 들은 체하며) 죄송합니다. 뭐라고 하셨죠?\",\n",
    "          \"Joker: What time?\",\n",
    "          \"조커: 몇 신가요?\",\n",
    "          \"Social Worker: It's 2:45.\",\n",
    "          \"사회복지사: 2시 45분이예요.\",\n",
    "          \"Social Worker: 전화번호를 기입하셔야 해요.\",\n",
    "          \"사회복지사: 2시 45분이예요.\",\n",
    "          \"Joker: What time?\",\n",
    "          \"조커: 몇 신가요?\"]\n",
    "\n",
    "print(sents)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### search() 함수를 이용하여 영어 문장과 한국어 문장을 찾아 출력하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sent in sents:\n",
    "    x = re.search('[a-zA-Z]+', sent)\n",
    "\n",
    "    if x:\n",
    "        print(\"'%s' is an English sentence.\" % sent)\n",
    "    else:\n",
    "        print(\"'%s' is a Korean sentence.\" % sent)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### search() 함수를 이용하여 영어 문장과 한국어 문장의 위치 찾기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_index = []\n",
    "kor_index = []\n",
    "for i, sent in enumerate(sents):\n",
    "    x = re.search('[a-zA-Z]+', sent)\n",
    "    \n",
    "    if x:\n",
    "        eng_index.append(i)\n",
    "    else:\n",
    "        kor_index.append(i)\n",
    "\n",
    "print(eng_index); print(kor_index)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 위 두 개 블록을 아래처럼 하나로 합할 수도 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_index = []\n",
    "kor_index = []\n",
    "for i, sent in enumerate(sents):\n",
    "    x = re.search('[a-zA-Z]+', sent)\n",
    "    \n",
    "    if x:\n",
    "        eng_index.append(i)\n",
    "    else:\n",
    "        kor_index.append(i)\n",
    "    \n",
    "    if x:\n",
    "        print(\"%s is an English sentence.\" % sent)\n",
    "    else:\n",
    "        print(\"%s is a Korean sentence.\" % sent)\n",
    "\n",
    "print(eng_index); print(kor_index)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 위에서 만든 eng_index와 kor_index 값을 이용하여 sents에서 영어 문장과 한국어 문장을 분리할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "english_sents = []\n",
    "korean_sents = []\n",
    "\n",
    "for i in eng_index:\n",
    "    english_sents.append(sents[i])\n",
    "\n",
    "for j in kor_index:\n",
    "    korean_sents.append(sents[j])\n",
    "\n",
    "print(english_sents); print(korean_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print([sents[i] for i in eng_index])\n",
    "print([sents[i] for i in kor_index])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### findall() 함수를 이용하여 영어 단어와 한글 단어를 찾아서 출력하기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = re.findall('[a-zA-Z]+', sents[0])\n",
    "yy = re.findall('[가-힣]+', sents[1])\n",
    "print(y); print(yy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "english_words = []\n",
    "korean_words = []\n",
    "for sent in sents:\n",
    "    eng = re.findall('[a-zA-Z]+', sent)\n",
    "    kor = re.findall('[ㄱ-ㅎ가-힣]+', sent)\n",
    "    if eng and not kor:\n",
    "        english_words.append(eng)\n",
    "    else:\n",
    "        korean_words.append(kor)\n",
    "\n",
    "print(english_words); print(korean_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "english_words_flat = [z for word in english_words for z in word]\n",
    "print(english_words_flat)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 문자열을 찾아 다른 문자열로 바꾸기: sub\n",
    "- 텍스트 파일을 처리할 때 가장 많이 사용하게 되는 정규식 관련 함수 중의 하나\n",
    "- 문자열을 찾아서 바꾸는(substitute) 기능을 가진 함수이므로, **search()**나 **findall()** 등의 찾기 함수와 달리 찾기 패턴 외에 바꾸기 패턴도 필요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(re.sub(pattern='\\d{4}', repl='XXXX', string='010-1234-5678'))\n",
    "print(re.sub(pattern='\\d{3}', repl='XXX', string='010-1234-5678'))\n",
    "print(re.sub(pattern='-', repl=' ', string='010-1234-5678'))\n",
    "print(re.sub(pattern='Tube ', repl='', string='Tube Ryan'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*sents*에서 등장인물 이름과 지문을 제거하고 대사만 남기기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents_no_names_direct = []\n",
    "\n",
    "for sent in sents:\n",
    "    x = re.sub('^.*: ', '', sent)\n",
    "    x = re.sub('\\(.*\\) ', '', x)\n",
    "    if x:\n",
    "        sents_no_names_direct.append(x)\n",
    "\n",
    "print(sents_no_names_direct)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "정규식을 이용하여 문자열 분리하기: **split()**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = '''Call me Ishmael. Some years ago—never mind how long precisely—having \\\n",
    "little or no money in my purse, and nothing particular to interest me \\\n",
    "on shore, I thought I would sail about a little and see the watery part \\\n",
    "of the world.'''\n",
    "\n",
    "words = re.split('[\\.\\?,! ]', sents)\n",
    "print(words)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*words*에는 빈 요소 즉 ''가 여러 개 포함되어 있다. 이 빈 요소들을 제거하려면 \"\"로 나타나는 요소들을 제거(remove)하면 된다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while '' in words:\n",
    "  words.remove('')\n",
    "print(words)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*words*에는 빈 요소 즉 ''가 여러 개 포함되어 있다. 이 빈 요소들을 제거하려면 **filter()** 함수를 다음과 같이 사용해도 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = re.split('[\\.\\?,! ]', sents)\n",
    "words = list(filter(None, words))\n",
    "print(words)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dfc0dc50c02b1a72f9c8c18b28cc5d6f7acf02306ca98ebb94c55727de830630"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
